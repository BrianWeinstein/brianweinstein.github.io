[{"content":"A few weeks ago, I was hypnotically scrolling through a vertical video, snap-scrolling, content consumption app when I encountered a bug: every video in my infinite feed was a â€œsponsoredâ€ post trying to get me to buy something.\nThat same week, there was a new app gaining attention: a vertical video, snap-scrolling, content consumption app in which every video was AI-generated.\nI paused for a moment and thought to myself, â€œAm I in hell?â€ I quickly decided to save that question for another day, then thought, â€œWhy not an app that isâ€¦ both?â€ So here, Iâ€™m embarrassed to announce my latest and dumbest creation yet: Slop \u0026amp; Shop, a vertical video, snap-scrolling, content consumption app in which every video is an AI-generated advertisement that tries to get you to buy something.\nThe app can only do two things: play AI-generated ads in an endless feed, and (plot twist!) encourage you to make our future less sloppy and less shoppy by donating to a few nonprofits committed to making high-quality, human-created knowledge available to the world, for free.\nPlay around with the app for a minute, then please tap one of the â€œShop nowâ€/â€œGet offerâ€/â€œSign upâ€ buttons to donate to worthy causes.\n Want to donate without slopping and shopping? Check out the following non-profits:\n Wikimedia Foundation (Wikipedia): For reliable human editing and review and ad-free knowledge. Donate or learn more. Creative Commons (CC): For tools that enable ethical sharing and reuse of creative works. Donate or learn more. The Internet Archive: For maintaining a permanent digital library and historical record. Donate or learn more.  ","permalink":"https://brianweinstein.github.io/posts/20251122-slop-and-shop/","summary":"Another vertical video, snap-scrolling, content consumption app. But for a cause!","title":"Slop \u0026 Shop: Another vertical video, snap-scrolling, content consumption app"},{"content":"I\u0026rsquo;m excited to share my new web app: Camera 3000: The Camera of the Future1.\nIt\u0026rsquo;s an AI-powered camera app that captures everything in the scene except the important details, so the photo you get is eerily similar to reality, but not quite right.2 It just barely â€œtakes a photo.â€\nI was loosely inspired by the â€œWhat is a photo?â€ debate and the rampant overuse of AI. I\u0026rsquo;m sure there\u0026rsquo;s something deep to say about both of these, but I have nothing new to add to that discourse. In reality, I just thought itâ€™d be fun to take those ideas to the extreme.\nHow it works: Given a photo, the app first uses the Gemini API to generate a detailed description of the image. Next, the Imagen API uses that description as a prompt to create a new, entirely-AI image of something that only sort of resembles the original scene.\nHow it\u0026rsquo;s made: In the spirit of overusing AI, I used Gemini/Canvas3 to write most of the appâ€™s code and followed its instructions to get the app live. In the spirit of over-overusing AI, I did almost everything it told me to do, too, including things I knew to be terrible, like publicly exposing my API key4. I\u0026rsquo;m sure there\u0026rsquo;s a lesson here somewhere.5\nThe app could use some polish: The error states are wonky, the UI is barebones, and I\u0026rsquo;ve given up on allowing a range of aspect ratios for the photo, but alas, it\u0026rsquo;s just a silly little novelty app. It\u0026rsquo;s functional, so just have fun with it.\nPlease be kind in your use of this app: I recognize that image generation can be used for malicious purposes, so the app will error out if a user attempts to generate harmful images. All of the AI generated images adhere to the SynthID digital watermarking standard too.\nPlease go try it out! The AI-everywhere future is already here, and itâ€™s partially running on a publicly exposed API key.6\n   Itâ€™s the â€œcamera of the futureâ€ in the same way that Dippin' Dots is the â€œice cream of the futureâ€: it\u0026rsquo;s not, and it\u0026rsquo;s not even good at being the camera / ice cream of the present. For what they are, Camera 3000 and Dippinâ€™ Dots are both incredibly energy inefficient too. The parallels are unparalleled. \u0026#x21a9;\u0026#xfe0e;\n This is somehow only the second-dumbest thing Iâ€™ve ever created. See my froyo map from 2016. Still ranking #1 on Google for â€œfroyo map nyc,â€ despite the map being broken ğŸ‰. \u0026#x21a9;\u0026#xfe0e;\n I used Gemini/Canvas. I just learned about Firebase Studio last week, which wouldâ€™ve made building this app 1000x easier. \u0026#x21a9;\u0026#xfe0e;\n Donâ€™t worry, I put some severe restrictions on the API keyâ€™s use. But still, please send your thoughts and prayers that I donâ€™t wake up to a million-dollar GCP bill. \u0026#x21a9;\u0026#xfe0e;\n In the spirit of over-over-overusing AI, I tried to use Gemini to write this blog post based on the appâ€™s code, but the generated text was just awful. The number of times I prompted â€œmake this sound less pompousâ€ â€¦ \u0026#x21a9;\u0026#xfe0e;\n Gemini wrote this closing sentence, though. Kinda funny, but still sounds a bit pompous. Iâ€™m sure thereâ€™s a lesson here too. \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://brianweinstein.github.io/posts/20250727-camera-3000/","summary":"An AI-powered camera app that captures everything in the scene except the important details.","title":"Camera 3000: The Camera of the Future"},{"content":"Defining clear KPIs is one of the most important things for a Product team, and (unfortunately) itâ€™s incredibly easy to do poorly. A good metric not only helps evaluate your productâ€™s performance, but also guides your team in building the right things to progress you toward your goal.\nThe framework described below is one Iâ€™ve used for a few years while working with teams that develop software products, and has been very helpful for me, my Data Science teammates, and our Product partners in measuring the success or failure of the products we build.\nShared definitions for objectives, KPIs, \u0026amp; productÂ metrics Before diving in, letâ€™s define a few relevant terms and how they relate to each other.\nAn objective is a description of the impact you want to have on the business. It should be qualitative, easy to understand, and somewhat obvious.\nA key performance indicator (KPI) (aka success metric) is the one, top-level metric that measures if your product is driving the outcome outlined in the Objective. This is the quantifiable top-level goal of your product, and should be a more quantitative statement of your objective. This is the metric you use to measure the performance of your product. Your success metric should be set longer-term and the definition of it shouldnâ€™t change very much, if at all, from quarter to quarter.\nA product metric measures the success of a specific feature. These are lower level metrics than KPIs: product metrics are something you should monitor to make sure your feature is facilitating the user behaviors that ultimately contribute to your KPI. Product metrics are also helpful in reporting: to ensure users are making use of the feature youâ€™ve built in the way that you intend.\nA health metric is used to monitor the technical health of a product. These are usually more pertinent to Engineers, but important for Product leaders to monitor as well. Performance metrics include things like page load time, API response time, etc. I wonâ€™t focus on them here, but want to call out that theyâ€™re distinct from these other types of metrics.\nYou may have different names for some of these concepts, but the ideas behind them should be more or less the same. Whatâ€™s most important is aligning on a common vocabulary for you and your team to use when talking about these ideas.\n(a badÂ metric)\nThe â€œgood metricâ€ checklist Since itâ€™s so easy to come up with the wrong metric, I like to think through a few criteria while brainstorming to ensure we settle on a metric suitable to the product. The criteria below apply to both KPIs and Product Metrics.\nSpecific \u0026amp; sensitive: Metrics should be specific to the product or feature, and need to be explicitly and quantitatively defined. The metric should also be sensitive enough to measure the impact we expect to see.\nRobust: To complement the sensitivity criteria above, we also need to make sure the metric is measuring only the effect of the product of interest, and that it isnâ€™t reactive to things we expect to change but donâ€™t control. Related to internal validity, we should try to avoid using a metric that can be significantly influenced by anything other than the product/feature we care about.\nMeasurable: This one is kind of obvious, but a metric must be something that we can actually measure. Itâ€™s not uncommon to ideate a bunch of â€œidealâ€ metrics that would perfectly measure the impact of your product, but end up being impossible or infeasible to really capture.\nInterpretable: Metrics should be easy to understand and agreed upon by those whose success is measured by the metric. Thereâ€™s often a tradeoff between simplicity and accuracy, and I typically err on the side of simplicity. A metric thatâ€™s hard to understand provides none of the benefits listed in the section below.\nAligned: Objectives, KPIs, and Product Metrics are hierarchical: every product should have an objective, a KPI that quantitatively measures progress toward achieving the objective, and then multiple product metrics to evaluate the performance of individual features. A productâ€™s KPI should also be aligned upward with higher level company metrics. Any movement in these metrics should also be reflected in and contribute to those above them in the hierarchy.\nThis certainly isnâ€™t an exhaustive list, but captures some of the most important criteria. If your metric meets all five of these conditions you should be in fairly good shape. If your metric doesnâ€™t meet one or more of these criteria, youâ€™ll likely need to ideate other metrics to use for your product.\nBenefits of thisÂ approach It takes a fair amount of effort to pick the right metric, and this is why it all matters!\nClarity of thought: Often what seems obvious to you is not so clear to others. Defining your goals \u0026amp; objectives in terms of hard numbers forces you to make your personal intuition clear to your team and to others at the company.\nOpportunity for innovation: KPIs and product metrics represent a goal, but donâ€™t mandate the path to get there. This frees up everyone on the team to think about new ways to move the needle rather than focusing on a prescribed solution.\nAlignment on goals: When you set your metrics, you tell your business partners what return it should expect from its investment in your team. If expectations arenâ€™t aligned, youâ€™re able to pivot before it becomes a problem.\nInsight for prioritization: You can use your pre-defined KPI to compare the potential impact of a handful of projects youâ€™re considering working on.\nProof of success: Itâ€™s much easier to communicate your impact on the organization when your goals are quantifiable.\nIndication of failure: By monitoring progress toward your goals, itâ€™s easy to correct course or sunset a product when your efforts arenâ€™t as effective as intended.\nNotes on this framework \u0026amp; furtherÂ reading This is a work in progress! Iâ€™ve added to and generalized this framework over the past few years as Iâ€™ve worked with different types of teams (based on their domains, operating style, degree of data literacy, etc.), and will keep doing so in the future.\nThereâ€™s a lot I donâ€™t touch on in this article, like leading \u0026amp; lagging indicators, reliability, defining targets for your metrics, balancing metrics, and more. For further reading, I like:\n Finding the metrics that matter for your product by the Product \u0026amp; Data team at Intercom How to grow product with KPIs and How to prioritize work with KPIs by Ilya Leyrikh A framework to define your product metrics by Zandre Coetzer 10 tips on how to choose the right key performance indicators by Roman Pichler  ","permalink":"https://brianweinstein.github.io/posts/20201222-defining-meaningful-metrics-for-product-teams/","summary":"A checklist for developing better product metrics \u0026amp;Â KPIs","title":"Defining meaningful metrics for productÂ teams"},{"content":"A few years ago as a Data Scientist I was presenting to co-workers an analysis Iâ€™d been working on. The presentation went fine and the work was well-received, but I could tell the group was a little underwhelmed. Towards the end of the presentation, one co-worker asked, â€œDid you find anything that surprised you? Anything we didnâ€™t already know?â€\nI had uncovered some new information, but most of what Iâ€™d found was well-aligned with what we already thought to be true. Still, I understood their sentiment. Any Data Scientist or Researcher will tell you that the most common thing we find when analyzing a dataset isâ€¦ nothing interesting. It happens constantly. Many of our findings corroborate what we and our business partners already thought to be true, even when weâ€™ve asked the right question. This can be frustrating for Data Scientists, Researchers, and our partners, but finding â€œnothing interestingâ€ is very different from finding â€œnothing useful,â€ and Iâ€™m a strong believer that finding nothing interesting after asking the right question is still worthy of celebration.\nThe Utility-Interest plane Before diving in, I want to emphasize the difference between a result being interesting and a result being useful. All analytical results (and the questions that spawned them) will fall somewhere in the Utility-Interest plane.\nA. Useful results that are also interesting are the holy grail. Findings from these analyses drum up tons of excitement with stakeholders and have the potential to create a huge impact.\nB. Useful results that arenâ€™t too interesting are less exciting, but are equally valuable! These are the only types of uninteresting results that are still defensible (the main topic of this post!). Useful, yet uninteresting results often arise when evaluating a hypothesis that everyone had assumed to be true, or when tackling a question thatâ€™d been answered through other methods in the past.\nC. Useless results that arenâ€™t very interesting are just a poor use of time. These come from asking the wrong question, and a question to which everyone already knew the answer. These wonâ€™t gain much traction with stakeholders, and the primary downside is just wasting your own time.\nD. Useless, but interesting results are dangerous. Very dangerous! Useless, yet interesting results arise when finding an exciting answer to the wrong question. Stakeholders can latch onto these findings and invest their own time into addressing a topic that should be lower priority.\nBy finding â€œnothing interestingâ€ in the data (i.e., a result in quadrant B) and presenting it to your stakeholders, youâ€™re able to make decisions with more confidence, ask meaningful follow-up questions, and increase stakeholdersâ€™ trust in using data in the future.\nKnowing when your intuition is right is just as important as knowing when itâ€™sÂ wrong Asking a question of the data means youâ€™re unsure about something: maybe a course of action to take, the reason behind something happening, or something else. Exploring a dataset and finding no surprises just means that, in this case, your intuition wasnâ€™t too far off.\nEven when you and your business partners have some intuition about a problem area, evaluating your hypotheses with data will let you know, without a doubt, if your hypotheses were true. Knowing when youâ€™re right is just as important as knowing when youâ€™re not, and by evaluating your hypotheses youâ€™ve learned to either maintain or change course.\nAsking meaningful follow-ups Assuming you asked a worthwhile question of the data, finding â€œnothing interestingâ€ will help inform what questions you should ask in the future. Any useful findingâ€Šâ€”â€Šwhether interesting or notâ€Šâ€”â€Šgives you more confidence in the problem area and refines your area of focus, helping you to ask better questions going forward.\nReinforcing confidence inÂ data Findings that contradict our intuition can be hard to acceptâ€Šâ€”â€Šespecially when the findings tell us that not only was our intuition wrong, but that our actions or plans were too. By finding and presenting â€œnothing interesting,â€ you help build trust between your stakeholders and the data, making it easier for them to accept information from you in the future, especially when itâ€™s counter to some of their beliefs.\nWhat to doÂ now Ask the right questions of your data. Of course, the points above only hold true if youâ€™ve asked the right question in the first place. Poor questions can sometimes lead to interesting answers, but the usefulness of these answers will be limited. My favorite way to refine a research question is to brainstorm with a cross-functional group of stakeholders (plus with this approach, you get stakeholder buy-in at the same time).\nCelebrate â€œnothing interesting.â€ A finding doesnâ€™t have to be interesting in order to be useful. Next time you find â€œnothing interesting,â€ remember to celebrate it.\n Further reading For resources on asking good questions, I really like Asking Great Questions as a Data Scientist by Kristen Kehrer, and How to solve a business problem using data by Laura Ellis. (Please let me know if you have any others!)\n","permalink":"https://brianweinstein.github.io/posts/20200219-in-defense-of-nothing-interesting/","summary":"A tribute to useful, but less interesting research findings","title":"In defense of â€œnothing interestingâ€"},{"content":"The Net Promoter Score is a widely-used survey question that companies use to measure customer satisfaction, loyalty, and growth.\nProponents of NPS are drawn to it because itâ€™s a single number that appearsâ€Šâ€”â€Šon the surface, at leastâ€Šâ€”â€Što be linked to some significant indicators of performance. NPS a bad measure of success, though. It uses a poorly phrased question, a response scale thatâ€™s entirely too big, and an absurd method of calculation.\nThere are other metrics you can use that will be more accurate, more interpretable, and much more predictive of satisfaction, loyalty, or growth.\nBackground The standard Net Promoter Score (NPS) question asks, â€œHow likely is it that you would recommend [company X] to a friend or colleague?â€ Respondents are given a scale ranging from 0â€“10, with 0 labeled with â€œNot at all likely,â€ and 10 labeled with â€œExtremely likely.â€\nUnder the NPS methodology, respondents who submit a 9 or 10 are considered â€œpromoters,â€ 7 or 8 are considered â€œpassivesâ€, and 0â€“6 are considered â€œdetractors.â€\nThe Net Promoter Score for a group of respondents is defined as the percentage of respondents who are promoters minus the percentage of respondents who are detractors.\nNPS = (# of promoters - # of detractors) / (total # of respondents)\nOrigin NPS was originally proposed in a December 2003 Harvard Business Review (HBR) article by Fred Reichheld, a director at the Bain \u0026amp; Company management consultancy. Reichheld proposed the score as a â€œloyaltyâ€ metric, which he defines as the â€œwillingness of someoneâ€¦ to make an investment or personal sacrifice in order to strengthen a relationship.â€\nReichheld tested eight survey questions among 4,000 consumers, and tracked these consumersâ€™ future purchases and referrals. He then measured the link between the survey responses and actual purchase and referral behaviors.\nThe NPS questionâ€Šâ€”â€Šâ€œHow likely is it that you would recommend [company X] to a friend or colleague?â€â€Šâ€”â€Šwas the 1st- or 2nd- most predictive question in 11 of Reichheldâ€™s 14 case studies, showing â€œthe strongest statistical correlation with repeat purchases or referrals.â€\nReichheld chose a 0-to-10 scale, where 10 meant â€œextremely likelyâ€ to recommend and 0 meant â€œnot at all likely.â€ He claimed that this scale was\n â€œsimple and unambiguous,â€ â€œdivide[s] customers into practical groups deserving differentâ€¦ organizational responses,â€ was â€œintuitive to customers when they assign grades,â€ and was intuitive â€œto employees and partners responsible for interpreting the results and taking action.â€  I disagree with all of these. More on that below.\nReichheld then grouped the 11-point scale into the three clusters: promoters, passives, and detractors. In his analysis, Reichheld found a strong correlation between companiesâ€™ net-promoter figures and their revenue growth rates.\nI highly recommend reading the original article with a critical eye: Itâ€™s full of anecdotes and correlations that Reichheld frames as causal relationships. Every few paragraphs he attempts to argue that NPS is superior over some alternative measurement in terms of assessing loyalty, growth, etc.; but fails to sufficiently justify his claims.\nWhy do companies useÂ NPS? NPS is popular. I mean very popular. Tons of companies ask customers the NPS question, and many use it to measure and assess their performance.\nProponents of NPS are drawn to it because itâ€™s a single number that appearsâ€Šâ€”â€Šon the surface, at leastâ€Šâ€”â€Što be linked to some significant KPIs. Itâ€™s also easy to measure and produces a statistic that changes easily over time.\nIf youâ€™re trying to get your organization to be more data-driven, then NPS is certainly better than nothing.\nWhy you shouldnâ€™t useÂ NPS Now that weâ€™ve gotten that out of the way, itâ€™s time to discuss the many, many shortcomings of NPS. The phrasing of the NPS question, the measurement scale it uses, and method of calculation all go against the basic principles of survey sciences.\nQuestion The NPS question asks a respondent to rate the likelihood of a hypothetical future; but strong, reliable survey questions ask respondents about their past behaviors, which tend to be much more predictive than forward-looking hypotheticals. â€œDo you plan to begin a diet in the next 6 weeks?â€, for example, is a very different question from â€œDid you begin a diet in the last 6 weeks?â€ The NPS question forces the respondent to predict an ideal, future self, as opposed to reporting on their actualized behaviors.\nThe HBR article also claims that the NPS question measures loyalty and growth. In reality, though, it fails to ask about either, and isnâ€™t necessarily what users of NPS are attempting to measure. In many cases, survey questions should be phrased to directly measure the quantity of interest.\nAn NPS-like question asking about actualized behavior would look more like, â€œIn the last 6 weeks, have you referred [company X] to a friend or colleague?â€\nReichheld promotes the NPS question as the most accurate one in predicting revenue growth rate. Proponents of NPS often fail to realize, however, that the NPS question was the most accurate from a set of 8 poorly phrased options in Reichheldâ€™s study. In Reichheldâ€™s findings, the NPS question wasnâ€™t even the most accurate predictor in all industries: In database software and computer systems, for example, other questions were stronger predictors of revenue growth rate.\nScale Responses collected from a large, 11-point scale are extremely noisy, and meaningful changes in ratings are hard to detect. On the NPS scale, the difference between a â€œ6â€ and a â€œ7â€ isnâ€™t clear in the survey analysis, and the lack of labels on the intermediate (i.e., non-extreme) choices also make the distinction very subjective to respondents. The NPS scale is poorly calibrated, and so are the responses.\nA better scale would use a 3-option Yes/Maybe/No system or a similar scale with 5 options. For any survey question, the response scale and number of options should be crafted to the individual question, and an 11-option scale is likely always too big.\nMethod of calculation The method of calculation is one of the stranger aspects of the NPS.\nThe bucketing methodology that groups respondents into Promoters, Passives, and Detractors ends up hiding some improvements and exaggerating others. Even if respondents were able to make meaningful distinctions between a â€œ5â€ and a â€œ6â€, or between a â€œ4â€ and a â€œ5â€, the bucketing method categorizes all of these into the â€œDetractorâ€ group, and these changes arenâ€™t reflected in the score. An extreme example is when a company with all â€œ0â€ ratings improves to having all â€œ6â€ ratings: this is a huge improvement, but the NPS methodology makes it so the score doesnâ€™t change at all. Some changes are also exaggerated by the method of calculation: the distinction between a â€œ6â€ (detractor) and a â€œ7â€ (passive), or between an â€œ8â€ (passive) and a â€œ9â€ (promoter) is exaggerated by the bucketing methodology.\nThe method of calculationâ€Šâ€”â€Šsubtracting the percentage of detractor respondents from the percentage of promoter respondentsâ€Šâ€”â€Šalso produces a metric thatâ€™s difficult to interpret and hides important information. All three of the following response sets, for example, produce an NPS of +60:\nFinding an alternative measurement NPS alternatives The most commonly used alternatives to NPS entail a rephrasing of the question and usage of a smaller scale.\nIf youâ€™re truly trying to measure growth or word-of-mouth promotion, I highly recommend Netflixâ€™s retrospective phrasing of an NPS-style question. In its early days, Netflix asked subscribers, â€œIn the last 6 weeks, did you recommend us to a friend or family member?â€ and gave respondents only a Yes/No scale to respond. Netflix also paired this with another question: they asked new subscribers, â€œWere you recommended to us by a friend or family member?â€\nOther companies, like Vox Mediaâ€™s Polygon, use a similar phrasing of the question with binary response options.\nThese are both significant improvements over the standard NPS question and scale.\nYouTube has a version that deviates less from the standard NPS question and scale, but still makes some significant improvements: They keep the standard NPS question, but instead use a smaller, labeled scale.\nSome alternatives that are even better In any survey, the quantity youâ€™re trying to measure should dictate both the question you ask and the scale you use. The questions and scales you design to measure growth, loyalty, satisfaction, etc. should each be customized for a given use case. A few examples for different measurements are outlined below.\n Growth: In the last 3 months, have you recommended [company X] to a friend, colleague, or family member? [Yes/No] Loyalty: In the last 6 weeks, have you considered [canceling your subscription, switching to another provider, etc.]? [Yes/No] Satisfaction: How satisfied are you with [company X]? [1 (Very dissatisfied), 2 (Dissatisfied), 3 (Neither), 4 (Satisfied), 5 (Very satisfied)]  What to doÂ now  Identify what youâ€™re trying to measure and write an appropriate question. If you want to measure word-of-mouth promotion or estimate future growth, then the â€œGrowthâ€ question above would be a good start. Measuring customer loyalty or customer satisfaction require entirely different questions, so make sure to ask about the thing youâ€™re trying to measure. Pick a reasonable scale for your question. 3- or 5-option satisfaction scales, and a Yes/No binary scale all capture accurate information and are easy for respondents to select from in a response. Use a simple, logical method of calculation. If your response scale has 5 or fewer options, then itâ€™s easy enough to report on the entire response distribution. If you need to have a single number to use in further analysis, then you might like a top-box or top-two-box percentage. You could also use the average of the numeric-encoded values, although you lose some information this way.  Whatever you do, pick something simpler and more interpretable than NPS.\nAdditional reading and references  Net Promoter Score Considered Harmful by Jared M. Spool On Surveys by Erika Hall Measuring the WeWork Member Experience by Tomer Sharon  ","permalink":"https://brianweinstein.github.io/posts/20180124-moving-beyond-the-net-promoter-score/","summary":"A guide to building a more meaningful metric","title":"Moving beyond the Net Promoter Score"},{"content":"The first debate in the 2016 presidential race was held on September 26. Itâ€™s no secret that Clinton and Trump are running on drastically different platforms, but how do they compare when it comes to their speech patterns and word choice? To quantify this, I dug into the data, using the debate transcript and natural language processing.\nI measured the sentiment of Clintonâ€™s and Trumpâ€™s responses, and examined how emotional their words were throughout the debate. I also looked at each candidateâ€™s most commonly used adjectives. Building off the work ofÂ Alvin Chang at Vox, I was also able to examine how the speech patterns of Clinton and Trump each changed when directly responding to and when skirting the questions.\nSentiment Using theÂ Google Cloud Natural Language API, I measured the sentiment of each candidateâ€™s answers. TheÂ polarityÂ of a response is a measure of how positive or negative it is, and theÂ magnitudeÂ indicates how much emotion the words convey. The chart below shows the polarity of each candidateâ€™s responses, weighted by the magnitude.\nTrump and Clinton matched each otherâ€™s polarity for the first half of the debate, but after his defense of stop-and-frisk around 9:50 PM, Trumpâ€™s words became much more negative.\nThroughout the rest of the debate â€” during the questions on birtherism, cyber security, homegrown terrorism, nuclear weapons, and Clintonâ€™s looks and stamina â€” Clinton became more positive and Trump more negative.\nThe combination of polarity and magnitudeÂ gives us the best understanding of each lineâ€™s overall sentiment, and each candidateâ€™s most positive and negative responses are postedÂ here.\nBraggadocios, and other adjectives I was also interested in the adjectives each candidate used most frequently during the debate. Using syntax analysis to extract each wordâ€™s part of speech, I identified the most-used adjectives of each candidate.\nAnswers vs non-answers AsÂ ChangÂ found, the candidates spent a lot of timeÂ notÂ answering Holtâ€™s questions â€” 48% of Clintonâ€™s words and a whopping 69% of Trumpâ€™s words were used in non-answers â€” and using the data Chang compiled, I was able to look at how the candidateâ€™s speech patterns differed when answering and not answering the questions.\nSentence subjects (â€œI alone can fix itâ€) Using part-of-speech tagging, I also identified theÂ subjectsÂ of each candidateâ€™s sentences. Clinton was more inclusive in her words, but only when directly responding to questions â€” using the plural â€œweâ€ more frequently than the singular â€œIâ€ â€” and the the opposite was true for her when avoiding a response. Trump, on the other hand, was always more likely to use â€œIâ€ over â€œweâ€.\nNon-answer phrases The words each candidate used when directly answering the questions are all, unsurprisingly, highly related to the questions Holt asked. Whatâ€™s interesting here are the topics the candidates defaulted to when avoiding a response.\n  A handful of my findings didnâ€™t make it into this post. If youâ€™re interested in more, thereâ€™s some additional analysis, including multiple classification models, in the projectâ€™sÂ GitHub repo. The text of this article (excluding this sentence) has polarity -0.4 and magnitude 15.5, so despite my best efforts itâ€™s leaningÂ slightlyÂ negative. Many thanks toÂ Alvin Chang and VoxÂ for their permission to use their annotated transcript, and toÂ Kelsey SchererÂ for designing the charts and lead image. Analysis was performed in R. Plots were generated using ggplot2, and then styled by Scherer using Sketch. The sentiment scores, part of speech tags, and all of the other NLP datasets can be found in theÂ GitHub repo.  ","permalink":"https://brianweinstein.github.io/posts/20161003-debate-nlp/","summary":"Natural language processing on the first 2016 presidential debate","title":"Speaking like a president"},{"content":"I love frozen yogurt. When I first moved to New York three years ago, I lived only 1/8th of a mile from the closest froyo shop. The convenience of this 4-minute walk is something I neither appreciated nor utilized enough at the time.\nAfter moving to Harlem last year, itâ€™s been harder than ever to satisfy my near-constant craving for this cold candy soup â€” Iâ€™m now a 24-minute walk to the nearest frozen yogurt.\nAs someone who loves data and has too much time to spare, I decided to find the locations in Manhattan with highest and lowest froyo densitiy. Inspired by Ben Wellingtonâ€™s work onÂ I Quant NY, I calculated the distance from every lot in Manhattan to the nearest froyo shopÂ and mapped it out.\nhttps://brianweinstein.cartodb.com/viz/27dd05e0-2486-11e6-98ba-0e98b61680bf/embed_map\nThe highest density of froyo is right around West 33rd St. and 8th Ave., with three shops within a 1-block radius. The lowest density is right in Harlem. The red circle on the map shows the location farthest from frozen yogurt. The record belongs toÂ 700 Esplanade Gardens Plaza, a co-op right by the 145th St. stop on the 3-train, with a 51-minute trek across Manhattan to the Pinkberry by Columbia.\nThe mapÂ shows all of the froyo shops in Manhattan, and you can click onÂ any lot to find the distance to the closest shop.\n  R code posted here. All distances in the map are measured usingÂ great-circle distanceÂ (i.e., â€as the crow fliesâ€), according to theÂ law of cosines. Frozen yogurt locations were found via theÂ Google Places Nearby Search API. The API returned some non-froyo-exclusive shops like Ben and Jerryâ€™s, which I kept in the dataset since they technically serve some frozen yogurt (although we all know these shops donâ€™tÂ reallyÂ count). I only included froyo shops that were in Manhattan, so some lots may have a closer shop than the one listed if we include those in other boroughs. Manhattan lot locations are fromÂ PLUTO. The map was created usingÂ CartoDB. Tons of inspiration for this came from Ben Wellingtonâ€™s work onÂ I Quant NY.  ","permalink":"https://brianweinstein.github.io/posts/20160531-froyo-nyc/","summary":"I love frozen yogurt. When I first moved to New York three years ago, I lived only 1/8th of a mile from the closest froyo shop. The convenience of this 4-minute walk is something I neither appreciated nor utilized enough at the time.\nAfter moving to Harlem last year, itâ€™s been harder than ever to satisfy my near-constant craving for this cold candy soup â€” Iâ€™m now a 24-minute walk to the nearest frozen yogurt.","title":"Mapping the frozen yogurt shop closest to each Manhattan apartment"},{"content":"              The wave equationÂ is a partial differential equation that describes the propagation of various types of waves.\nThe equation appears throughout many fields in physics, including acoustics, fluid dynamics,Â electromagnetism, and quantum mechanics. With some modifications, it can even describe the spread of traffic jams on busy highways!\nThe one-dimensional equation was first discovered by dâ€™AlembertÂ in 1746Â as he studied how vibrations propagated through a string, and the two- and three-dimensional equations were solvedÂ soon afterÂ by EulerÂ during his study of acoustics.\nThe simulations above show the propagation of a disturbance on a two-dimensional surface for two different sets of boundary conditions [1]Â [2].\n Mathematica code posted here.\n","permalink":"https://brianweinstein.github.io/posts/20150128-wave-equation/","summary":"The wave equationÂ is a partial differential equation that describes the propagation of various types of waves.\nThe equation appears throughout many fields in physics, including acoustics, fluid dynamics,Â electromagnetism, and quantum mechanics. With some modifications, it can even describe the spread of traffic jams on busy highways!\nThe one-dimensional equation was first discovered by dâ€™AlembertÂ in 1746Â as he studied how vibrations propagated through a string, and the two- and three-dimensional equations were solvedÂ soon afterÂ by EulerÂ during his study of acoustics.","title":"Wave Equation"},{"content":"                  A Platonic solid is a polyhedronÂ where (1) each face is the same regular polygon, and (2) each vertex joins the same number of faces.\nThe Platonic solids are highlyÂ symmetrical, and, in three dimensions, only five such solids can exist: the tetrahedron, cube, octahedron, dodecahedron, and icosahedron.\nThis was first proven in Euclidâ€™s Elements around 300Â B.C., and has since been more rigorously proven using the Euler characteristic. The proofs are relatively easy to follow, and if youâ€™re interested you can check them out both here and here.\n Mathematica code:\npSolids={\u0026quot;Tetrahedron\u0026quot;,\u0026quot;Cube\u0026quot;,\u0026quot;Octahedron\u0026quot;,\u0026quot;Dodecahedron\u0026quot;,\u0026quot;Icosahedron\u0026quot;} Manipulate[Graphics3D[ {Opacity[0.8],Rotate[PolyhedronData[pSolids[[n]],\u0026quot;Faces\u0026quot;],th,{0,0,1}], Opacity[0],Circumsphere[PolyhedronData[pSolids[[n]], \u0026quot;VertexCoordinates\u0026quot;][[1;;4]]]}, Boxed-\u0026gt;False,SphericalRegion-\u0026gt;True],{n,1,5,1},{th,0,2\\[Pi]}] ","permalink":"https://brianweinstein.github.io/posts/20150120-platonic-solids/","summary":"A Platonic solid is a polyhedronÂ where (1) each face is the same regular polygon, and (2) each vertex joins the same number of faces.\nThe Platonic solids are highlyÂ symmetrical, and, in three dimensions, only five such solids can exist: the tetrahedron, cube, octahedron, dodecahedron, and icosahedron.\nThis was first proven in Euclidâ€™s Elements around 300Â B.","title":"Platonic Solids"},{"content":"                      Imagine n runners on a circular track of length 1. The runners start from the same spot at the same time, and each has a distinct, constant speed. A runner is considered â€œlonelyâ€ whenever it is a distance of at least 1/n from every other runner. The Lonely Runner Conjecture (LRC) states that each runner will eventually, at some point in time, be lonely.\nSaid differently, the LRC states that for each runner, the spacing around it will eventually be greater than or equal to the spacing it would experience if the all of the runners were equally distributed around the track.\nThe conjecture has been proven to be true for 7 or fewer runners, but, interestingly enough, has never been proven to work for all cases of 8 or more runners. [In my 8-runner simulation above, Iâ€™ve only shown that it works for a specific set of runner speeds â€” I havenâ€™t proven that it works for all sets of speeds.]\nIn the GIFs above, an arc appears around a runner whenever the runner is lonely, and the color of a runner fades after itâ€™s been lonely at least once.\n Mathematica code posted here.\nAdditional sources not linked above: [1] [2] [3]\n","permalink":"https://brianweinstein.github.io/posts/20141225-lonely-runner-conjecture/","summary":"Imagine n runners on a circular track of length 1. The runners start from the same spot at the same time, and each has a distinct, constant speed. A runner is considered â€œlonelyâ€ whenever it is a distance of at least 1/n from every other runner. The Lonely Runner Conjecture (LRC) states that each runner will eventually, at some point in time, be lonely.","title":"Lonely Runner Conjecture"},{"content":"                      Two weeks ago, the ESA made history by landing a spacecraft on a comet. The spacecraft, named Philae, was carried to Comet 67P by a larger space probe named Rosetta.\nDetermining where Philae would land was a big step in this mission. Many attributes about the comet, including its topography, were taken into account. To help in this process, the ESA derived a 3D model of the comet\u0026rsquo;s surface, and the data (made up of over 30,000 measurements) was recently released.\nThe images above use ESA data to model the surface of 67P. By adjusting lighting and orientation, actual photos taken by Rosetta (images 3 and 5) can be reproduced.\nYou can play around with the model yourself!\nEither use the code below in Mathematica or on the Wolfram Programming Cloud (with a free account), or play with the model online by clicking here*.\n *This link will expire on Dec 23, 2014, after which you\u0026rsquo;ll have to upload the .obj file directly to the online viewer.\nMathematica code:\nobjLink = \u0026quot;http://sci.esa.int/science-e/www/object/doc.cfm?fobjectid=54726\u0026quot;; comet = Import[objLink, \u0026quot;OBJ\u0026quot;]; pts = Import[objLink, {\u0026quot;OBJ\u0026quot;, \u0026quot;VertexData\u0026quot;}]; ListSurfacePlot3D[pts, MaxPlotPoints -\u0026gt; 20, Mesh -\u0026gt; All, MeshStyle -\u0026gt; Opacity[0.4]] Show[comet, Background -\u0026gt; Black, Lighting -\u0026gt; {{\u0026quot;Directional\u0026quot;, LightGray, {-7, -10, 10}}}] Additional sources: [1] [2] [3]\nImages 3 \u0026amp; 5: ESA/Rosetta/NAVCAM, CC BY-SA IGO 3.0\n","permalink":"https://brianweinstein.github.io/posts/20141124-comet-67p/","summary":"Two weeks ago, the ESA made history by landing a spacecraft on a comet. The spacecraft, named Philae, was carried to Comet 67P by a larger space probe named Rosetta.\nDetermining where Philae would land was a big step in this mission. Many attributes about the comet, including its topography, were taken into account.","title":"Modeling Comet 67P"},{"content":"                  A harmonograph is a mechanical device consisting of two or more pendulums attached to a pen. The swinging pendulums control the motion of the pen, tracing out a geometric pattern on a sheet of paper.\nSince the system is damped by friction, the pattern spirals in on itself as time progresses.\nEach of the GIFs above simulate the output of a 4-pendulum system (modeled after a harmonograph as configured in this video). The different outputs are generated by using different pendulum length ratios in each simulation.\n Mathematica code posted here.\nAdditional source not linked above.\n","permalink":"https://brianweinstein.github.io/posts/20141110-harmonographs/","summary":"A harmonograph is a mechanical device consisting of two or more pendulums attached to a pen. The swinging pendulums control the motion of the pen, tracing out a geometric pattern on a sheet of paper.\nSince the system is damped by friction, the pattern spirals in on itself as time progresses.\nEach of the GIFs above simulate the output of a 4-pendulum system (modeled after a harmonograph as configured in this video).","title":"Harmonographs"},{"content":"                  A curve of constant width is a convex, two-dimensional shape that, when rotated inside a square, always makes contact with all four sides.\nA circle is the most obvious (but somewhat trivial) example. Some non-trivial examples are the odd-sided Reuleaux polygons â€” the first four of which are shown above.\nSince they don\u0026rsquo;t have fixed axes of rotation, curves of constant width (except the circle) have few practical applications. One notable use of the Reuleaux triangle, though, is in drilling holes in the shape of a slightly rounded square (watch one of the triangle\u0026rsquo;s vertices and notice the shape it traces out as it spins).\nOn a less technical note, all curves of constant width are solutions to the brainteaser, \u0026ldquo;Other than a circle, what shape can you make a manhole cover such that it can\u0026rsquo;t fall through the hole it covers?\u0026rdquo;\n Mathematica code posted here.\nAdditional source not linked above.\n","permalink":"https://brianweinstein.github.io/posts/20141020-curves-of-constant-width/","summary":"A curve of constant width is a convex, two-dimensional shape that, when rotated inside a square, always makes contact with all four sides.\nA circle is the most obvious (but somewhat trivial) example. Some non-trivial examples are the odd-sided Reuleaux polygons â€” the first four of which are shown above.\nSince they don\u0026rsquo;t have fixed axes of rotation, curves of constant width (except the circle) have few practical applications.","title":"Curves of Constant Width and Odd-Sided Reuleaux Polygons"},{"content":"              Evidence-based theories on the structure of atoms have been around since the early 1800s. Daltonâ€™s billiard ball model was the first on the map, and with further discoveries and experiments â€” like Thompsonâ€™s discovery of the electron and Rutherfordâ€™s gold foil experiment â€” improved models of atomic structure were introduced.\nThe first GIF above shows Rutherfordâ€™s planetary model, which was proposed in 1911. In his model, negatively-charged electrons orbit an incredibly small, dense nucleus of positive charge. Despite being a completely incorrect model, most people still think this is what atoms really look like*. This is not an atom. Itâ€™s physically impossible for electrons to stably orbit like this, and the idea of orbiting electrons was entirely replaced by 1926.\nI canâ€™t say what an atom actually looks like, but the most accurate model we have today is governed by the laws of quantum mechanics. The location of an electron is determined by a probability distribution, called an atomic orbital, which tells us the probability of an electron existing in any specific region around a nucleus. The second image shows the surface around a hydrogen nucleus on which an excited electron is most likely to exist.\n Mathematica code posted here.\n*Advertisements and popular science articles incorrectly represent atoms all the time. Even the US Atomic Energy Commission and the International Atomic Energy Agency use the Rutherford model in their logos!\n","permalink":"https://brianweinstein.github.io/posts/20140922-atomic-models/","summary":"Evidence-based theories on the structure of atoms have been around since the early 1800s. Daltonâ€™s billiard ball model was the first on the map, and with further discoveries and experiments â€” like Thompsonâ€™s discovery of the electron and Rutherfordâ€™s gold foil experiment â€” improved models of atomic structure were introduced.\nThe first GIF above shows Rutherfordâ€™s planetary model, which was proposed in 1911.","title":"Atomic Models"},{"content":"              Cops and Robbers is a mathematical game in which pursuers (cops) attempt to capture evaders (robbers). The game is one of many pursuit-evasion games, each of which is governed by a different set of rules. The general goal of these problems is to determine the number of pursuers required to capture a given number of evaders.\nThe GIFs above show two versions of the game. The first is similar to the standard Cops and Robbers rendition, and the second is best described as \u0026ldquo;Zombies and Humans\u0026rdquo;.\nIn both versions, an evader moves in the direction that gets it furthest away from the pursuers (focusing more on the closer pursuers), and a pursuer moves in the direction that gets it closest to the evaders (focusing more on the closer evaders).\nIn the first simulation, members of both groups have a constant speed. In the second simulation, members of a group move more quickly the closer they are to members of the opposite group, and slower when further away.\n Mathematica code posted here.\nAdditional sources not linked above: [1] [2]\n","permalink":"https://brianweinstein.github.io/posts/20140902-cops-and-robbers/","summary":"Cops and Robbers is a mathematical game in which pursuers (cops) attempt to capture evaders (robbers). The game is one of many pursuit-evasion games, each of which is governed by a different set of rules. The general goal of these problems is to determine the number of pursuers required to capture a given number of evaders.","title":"Cops and Robbers (and Zombies and Humans)"},{"content":"              A reflector is a type of antenna that receives and focuses various types of signals. Reflectors have numerous applications, from satellite dishes and telescopes, to long-distance microphones and car headlights. One common feature of these examples is their parabolic shape, giving them the name parabolic reflectors.\nIt turns out that paraboloids are the perfect shape for focusing signals from distant sources. When pointed directly at the the incoming signal, a parabolic reflector (GIF 1) collects the signal to a single focal point, where a receiver, called a feed horn, is placed to collect the focused transmission.\nIn many applications, parabolic reflectors are too costly to produce, so spherical reflectors (GIF 2) are used instead. The disadvantage of spherical reflectors is that they have multiple focal points, and therefore produce blurry results.\n Mathematica code posted here.\nThis code is incredibly messy and I guarantee thereâ€™s a better way to calculate this. Please contact me if you have suggestions!\n","permalink":"https://brianweinstein.github.io/posts/20140811-signal-collection-parabolic-reflectors/","summary":"A reflector is a type of antenna that receives and focuses various types of signals. Reflectors have numerous applications, from satellite dishes and telescopes, to long-distance microphones and car headlights. One common feature of these examples is their parabolic shape, giving them the name parabolic reflectors.\nIt turns out that paraboloids are the perfect shape for focusing signals from distant sources.","title":"Signal Collection and Parabolic Reflectors"},{"content":"A Taylor series is a way to represent a function in terms of polynomials. Since polynomials are usually much easier to work with than complicated functions, Taylor series have numerous applications in both math and physics.\nThere are many equations in physics â€” like the one describing the motion of a pendulum â€” that are impossible to solve in terms of elementary functions. \u0026ldquo;Approximations using the first few terms of a Taylor series can make [these] otherwise unsolvable problems\u0026rdquo; solvable for a restricted area of interest [1].\nThe GIF above shows the five-term Taylor series approximation of a sine wave about x=0.\n Mathematica code:\nf[x_] := Sin[x] ts[x_, a_, nmax_] := Sum[(Derivative[n][f][a]/n!)*(x - a)^n, {n, 0, nmax}] Manipulate[Plot[{f[x], ts[x, 0, nmax]}, {x, -2*Pi, 2*Pi}, PlotRange -\u0026amp;gt; {-1.45, 1.45}, PlotStyle -\u0026amp;gt; {{Thick, Cyan}, {Thick, Dotted, Yellow}}, AxesStyle -\u0026amp;gt; LightGray, Background -\u0026amp;gt; Darker[Gray, 0.8]], {nmax, 1, 30, 1}] ","permalink":"https://brianweinstein.github.io/posts/20140730-taylor-series-approximations/","summary":"A Taylor series is a way to represent a function in terms of polynomials. Since polynomials are usually much easier to work with than complicated functions, Taylor series have numerous applications in both math and physics.\nThere are many equations in physics â€” like the one describing the motion of a pendulum â€” that are impossible to solve in terms of elementary functions. \u0026ldquo;Approximations using the first few terms of a Taylor series can make [these] otherwise unsolvable problems\u0026rdquo; solvable for a restricted area of interest [1].","title":"Taylor Series Approximations"},{"content":"              Time for an experiment! Find a book and secure it shut using tape or a rubber band. Now experiment with spinning the book while tossing it into the air. Youâ€™ll notice that when the book is spun about its longest or shortest axis it rotates stably, but when spun about its intermediate-length axis it quickly wobbles out of control.\nEvery rigid body has three special, or principal axes about which it can rotate. For a rectangular prism â€” like the book in our experiment â€” the principal axes run parallel to the shortest, intermediate-length, and longest edges, each going through the prismâ€™s center of mass. These axes have the highest, intermediate, and lowest moments of inertia, respectively.\nWhen the book is tossed into the air and spun, either about its shortest or longest principal axis, it continues to rotate about that axis forever (or until it hits the floor). For these axes, this indefinite, stable rotation occurs even when the axis of rotation is slightly perturbed.\nWhen spun about its intermediate principal axis, though, the book also continues to rotate about that axis indefinitely, but only if the axis of rotation is exactly in the same direction as the intermediate principal axis. In this case, even the slightest perturbation causes the book to wobble out of control.\nThe first simulation above shows a rotation about the unstable intermediate axis, where a slight perturbation causes the book to wobble out of control. The second and third simulations show rotations about the two stable axes.\nUnfortunately, as far as my understanding goes, there\u0026rsquo;s no intuitive, non-mathematical explanation as to why rotations about the intermediate principal axis are unstable. If you\u0026rsquo;re interested, you can find the stability analysis here.\n Mathematica code posted here.\nAdditional sources not linked above: [1] [2] [3] [4]\n","permalink":"https://brianweinstein.github.io/posts/20140713-rotational-stability/","summary":"Time for an experiment! Find a book and secure it shut using tape or a rubber band. Now experiment with spinning the book while tossing it into the air. Youâ€™ll notice that when the book is spun about its longest or shortest axis it rotates stably, but when spun about its intermediate-length axis it quickly wobbles out of control.","title":"Rotational Stability"},{"content":"Gabrielâ€™s Horn is a three-dimensional horn shape with the counterintuitive property of having a finite volume but an infinite surface area.\nThis fact results in the Painterâ€™s Paradox â€” A painter could fill the horn with a finite quantity of paint, â€œand yet that paint would not be sufficient to coat [the hornâ€™s] inner surfaceâ€ [1].\nIf the hornâ€™s bell had, for example, a 6-inch radius, weâ€™d only need about a half gallon of paint to fill the horn all the way up. Even though this half gallon is enough to entirely fill the horn, itâ€™s not enough to even coat a fraction of the inner wall!\nThe mathematical explanation is a bit confusing if you havenâ€™t taken a first course in calculus, but if youâ€™re interested, you can check it out here.\n Mathematica code:\nx[u_, v_] := u y[u_, v_] := Cos[v]/u z[u_, v_] := Sin[v]/u Manipulate[ParametricPlot3D[{{x[u, v], y[u, v], z[u, v]}}, {u, 1, umax}, {v, 0, 2*Pi}, PlotRange -\u0026amp;gt; {{0, 20}, {-1, 1}, {-1, 1}}, Mesh -\u0026amp;gt; {Floor[umax], 20}, Axes -\u0026amp;gt; False, Boxed -\u0026amp;gt; False], {{umax, 20}, 1.1, 20}] Additional source not linked above.\n","permalink":"https://brianweinstein.github.io/posts/20140629-painters-paradox/","summary":"Gabrielâ€™s Horn is a three-dimensional horn shape with the counterintuitive property of having a finite volume but an infinite surface area.\nThis fact results in the Painterâ€™s Paradox â€” A painter could fill the horn with a finite quantity of paint, â€œand yet that paint would not be sufficient to coat [the hornâ€™s] inner surfaceâ€ [1].\nIf the hornâ€™s bell had, for example, a 6-inch radius, weâ€™d only need about a half gallon of paint to fill the horn all the way up.","title":"Gabrielâ€™s Horn and the Painterâ€™s Paradox"},{"content":"The Lagrangian points are the five locations in an orbital system where the combined gravitational force of two large masses is exactly canceled out by the centrifugal force arising from the rotating reference frame.\nAt these five points, the net force on a third body (of negligible mass) is 0, allowing the third object to be completely stationary relative to the two other masses. That is, when placed at any of these points, the third body stays perfectly still in the rotating frame.\nThe first image shows the fields due to the first mass, the second mass, and the rotating reference frame. When added together, these fields generate the effective field shown in the second image. The five Lagrangian points are indicated with gray spheres.\nThe first three Lagrangian points (labeled L1, L2, and L3) lie in line with the two larger bodies and are considered metastable equilibria. L4 and L5 lie 60Â° ahead of and behind the second body in its orbit and are considered stable equilibria.\nLagrangian points offer unique advantages for space research, and the Lagrangian points of the Sun-Earth system are currently home to four different satellites.\n Mathematica code posted here.\nAdditional sources not linked above: [1] [2] [3] [4] [5]\n","permalink":"https://brianweinstein.github.io/posts/20140609-lagrangian-points/","summary":"The Lagrangian points are the five locations in an orbital system where the combined gravitational force of two large masses is exactly canceled out by the centrifugal force arising from the rotating reference frame.\nAt these five points, the net force on a third body (of negligible mass) is 0, allowing the third object to be completely stationary relative to the two other masses. That is, when placed at any of these points, the third body stays perfectly still in the rotating frame.","title":"Lagrangian Points"},{"content":"                  The Doppler effect is the shift in the frequency of a wave observed when the source of the wave (or the medium through which the wave travels) is moving relative to the observer.\nWeâ€™re most familiar with the Doppler effect as it appears in sound waves traveling through air (i.e., pressure waves) â€“ think of how the pitch of a siren drops as an emergency vehicle passes you. The first GIF shows a stationary source and the second shows a source moving to the right at 40% the speed of sound. Notice in the second GIF how the wavefronts are closer together in front of the source (producing a higher frequency) and further apart behind it (producing a lower frequency).\nThe Doppler effect is interesting in its own right, but things get much more exciting when the source travels at speeds greater than or equal to the speed of sound.\nWhen the source travels at the speed of sound (GIF 3) the source will always be at the leading edge of the waves it produces, and when traveling faster than the speed of sound (GIF 4), the source will always be in front of the waves it produces. In both of these cases, notice how the waves overlap with each other. The high pressure areas of each wave constructively interfere and produce a region of extremely high pressure (much higher than in the surrounding areas). This rapid rise in air pressure is a shock wave, and the sound associated with it is a sonic boom.\nIn each of the GIFs above we see the radiating wavefronts on the left, and the pressure distribution and interference of the waves on the right.\n Mathematica code posted here.\nAdditional source not linked above.\n","permalink":"https://brianweinstein.github.io/posts/20140528-sonic-boom-doppler-effect/","summary":"The Doppler effect is the shift in the frequency of a wave observed when the source of the wave (or the medium through which the wave travels) is moving relative to the observer.\nWeâ€™re most familiar with the Doppler effect as it appears in sound waves traveling through air (i.e., pressure waves) â€“ think of how the pitch of a siren drops as an emergency vehicle passes you.","title":"Sonic Booms and the Doppler Effect"},{"content":"A chaotic system is one in which infinitesimal differences in the starting conditions lead to drastically different results as the system evolves.\nSummarized by mathematician Edward Lorenz, \u0026ldquo;Chaos [is] when the present determines the future, but the approximate present does not approximately determine the future.\u0026rdquo;\nThere\u0026rsquo;s an important distinction to make between a chaotic system and a random system. Given the starting conditions, a chaotic system is entirely deterministic. A random system, on the other hand, is entirely non-deterministic, even when the starting conditions are known. That is, with enough information, the evolution of a chaotic system is entirely predictable, but in a random system there\u0026rsquo;s no amount of information that would be enough to predict the system\u0026rsquo;s evolution.\nThe simulations above show two slightly different initial conditions for a double pendulum â€” an example of a chaotic system. In the left animation both pendulums begin horizontally, and in the right animation the red pendulum begins horizontally and the blue is rotated by 0.1 radians (â‰ˆ 5.73Â°) above the positive x-axis. In both simulations, all of the pendulums begin from rest.\nFor more information on how to solve for the motion of a double pendulum, check out my video here.\n Mathematica code posted here.\n","permalink":"https://brianweinstein.github.io/posts/20140519-chaos-and-the-double-pendulum/","summary":"A chaotic system is one in which infinitesimal differences in the starting conditions lead to drastically different results as the system evolves.\nSummarized by mathematician Edward Lorenz, \u0026ldquo;Chaos [is] when the present determines the future, but the approximate present does not approximately determine the future.\u0026rdquo;\nThere\u0026rsquo;s an important distinction to make between a chaotic system and a random system. Given the starting conditions, a chaotic system is entirely deterministic. A random system, on the other hand, is entirely non-deterministic, even when the starting conditions are known.","title":"Chaos and the Double Pendulum"},{"content":"A couple of weeks ago I made a post about the classical three-body problem, which involves determining the motion of three masses interacting via gravity over time.\nIn that simulation, the three masses were restricted to a plane. Even though we live in three spatial dimensions, a two-dimensional model for celestial orbits isnâ€™t such a bad approximation â€“ the orbits of masses in celestial system are often within a few degrees of the same plane.\nIn the simulation above Iâ€™ve built in a third spatial dimension and modeled a system in which the masses do not stay within the same plane. In this simulation, the green and red bodies are 9 and 13 times more massive than the blue body, respectively.\n The Mathematica code for this one was a bit long, so I\u0026rsquo;ve posted it here.\n","permalink":"https://brianweinstein.github.io/posts/20140512-three-body-problem-3d/","summary":"A couple of weeks ago I made a post about the classical three-body problem, which involves determining the motion of three masses interacting via gravity over time.\nIn that simulation, the three masses were restricted to a plane. Even though we live in three spatial dimensions, a two-dimensional model for celestial orbits isnâ€™t such a bad approximation â€“ the orbits of masses in celestial system are often within a few degrees of the same plane.","title":"Three-Body Problem in 3D"},{"content":"              An orientable surface is a surface on which itâ€™s possible to make a consistent definition of direction. Most surfaces we encounter â€“ like spheres, planes, and tori (doughnut shapes) â€“ are orientable. When visualized in three dimensions, orientable surfaces have two distinct sides.\nNon-orientable surfaces, on the other hand, have only one side. From Wikipedia, â€œThe essence of one-sidedness is that [an] ant can crawl from one side of the surface to the â€˜otherâ€™ without going through the surface or flipping over an edge, but simply by crawling far enough.â€ At any point on a non-orientable surface itâ€™s impossible to uniquely define, for example, the â€œclockwiseâ€ direction.\nThe GIFs above show two examples of non-orientable surfaces: a Klein bottle and a MÃ¶bius strip.\n Mathematica code [Klein Bottle]:\nxk[u_, v_] := (-2/15)*Cos[u]*(3*Cos[v] - 30*Sin[u] + 90*Cos[u]^4*Sin[u] - 60*Cos[u]^6*Sin[u] + 5*Cos[u]*Cos[v]*Sin[u]) yk[u_, v_] := (-15^(-1))*Sin[u]*(3*Cos[v] - 3*Cos[u]^2*Cos[v] - 48*Cos[u]^4*Cos[v] + 48*Cos[u]^6*Cos[v] - 60*Sin[u] + 5*Cos[u]*Cos[v]*Sin[u] - 5*Cos[u]^3*Cos[v]*Sin[u] - 80*Cos[u]^5*Cos[v]*Sin[u] + 80*Cos[u]^7*Cos[v]*Sin[u]) zk[u_, v_] := (2/15)*(3 + 5*Cos[u]*Sin[u])*Sin[v] kb[u_, v_] := {xk[u, v], yk[u, v], zk[u, v]} Manipulate[ParametricPlot3D[kb[u, v], {u, 0, umax}, {v, 0, 2*Pi}, PlotRange -\u0026gt; {{-1.8, 2}, {0, 4.5}, {-0.75, 0.75}}, Axes -\u0026gt; False, Boxed -\u0026gt; False, PlotStyle -\u0026gt; {Opacity[0.65]}, Mesh -\u0026gt; {20, 11}, MeshStyle -\u0026gt; Directive[Gray, Opacity[0.65], Thickness[0.003]]], {umax, 0.001, Pi}] Mathematica code [MÃ¶bius Strip]:\nxm[u_, v_] := (1 + (v/2)*Cos[u/2])*Cos[u] ym[u_, v_] := (1 + (v/2)*Cos[u/2])*Sin[u] zm[u_, v_] := (v/2)*Sin[u/2] ms[u_, v_] := {xm[u, v], ym[u, v], zm[u, v]} Manipulate[ParametricPlot3D[ ms[u, v], {u, 0, umax}, {v, -1, 1}, PlotRange -\u0026gt; {{-1.1, 1.5}, {-1.5, 1.5}, {-0.5, 0.5}}, PlotStyle -\u0026gt; {Opacity[0.65]}, Axes -\u0026gt; False, Boxed -\u0026gt; False, Mesh -\u0026gt; {20, 5}, MeshStyle -\u0026gt; Directive[Gray, Opacity[0.65], Thickness[0.003]]], {umax, 0.001, 2*Pi}] ","permalink":"https://brianweinstein.github.io/posts/20140505-non-orientable-surfaces/","summary":"An orientable surface is a surface on which itâ€™s possible to make a consistent definition of direction. Most surfaces we encounter â€“ like spheres, planes, and tori (doughnut shapes) â€“ are orientable. When visualized in three dimensions, orientable surfaces have two distinct sides.\nNon-orientable surfaces, on the other hand, have only one side. From Wikipedia, â€œThe essence of one-sidedness is that [an] ant can crawl from one side of the surface to the â€˜otherâ€™ without going through the surface or flipping over an edge, but simply by crawling far enough.","title":"Non-Orientable Surfaces"},{"content":"Given the starting positions, velocities, and masses of three objects interacting via gravity, the classical three-body problem involves determining the motions of the three particles throughout time.\nWhatâ€™s cool about the three-body system is that itâ€™s impossible to solve for the motions of the objects exactly. That is, we canâ€™t write down an equation that describes the system. Instead of finding an exact solution, we solve the system numerically, which amounts to finding an accurate approximation.\nThe three-body problem is an example of a chaotic system, meaning that even a slight change in the starting conditions drastically changes the time-evolution of the system.\nThe GIF above shows a planar (i.e., two-dimensional) three-body system.\n Mathematica code:\nG = 1; time = 30; mA = 1; xA0 = 0; yA0 = 0; vxA0 = 0; vyA0 = 0; mB = 1; xB0 = 1; yB0 = 0; vxB0 = 0; vyB0 = 0; mC = 1; xC0 = 0; yC0 = 0.8; vxC0 = 0; vyC0 = 0; soln1 = NDSolve[ {mA*Derivative[2][xA][t] == -((G*mA*mB*(xA[t] - xB[t]))/((xA[t] - xB[t])^2 + (yA[t] - yB[t])^2)^(3/2)) - (G*mA*mC*(xA[t] - xC[t]))/((xA[t] - xC[t])^2 + (yA[t] - yC[t])^2)^(3/2), mA*Derivative[2][yA][t] == -((G*mA*mB*(yA[t] - yB[t]))/((xA[t] - xB[t])^2 + (yA[t] - yB[t])^2)^(3/2)) - (G*mA*mC*(yA[t] - yC[t]))/((xA[t] - xC[t])^2 + (yA[t] - yC[t])^2)^(3/2), mB*Derivative[2][xB][t] == -((G*mB*mC*(xB[t] - xC[t]))/((xB[t] - xC[t])^2 + (yB[t] - yC[t])^2)^(3/2)) - (G*mB*mA*(xB[t] - xA[t]))/((xB[t] - xA[t])^2 + (yB[t] - yA[t])^2)^(3/2), mB*Derivative[2][yB][t] == -((G*mB*mC*(yB[t] - yC[t]))/((xB[t] - xC[t])^2 + (yB[t] - yC[t])^2)^(3/2)) - (G*mB*mA*(yB[t] - yA[t]))/((xB[t] - xA[t])^2 + (yB[t] - yA[t])^2)^(3/2), mC*Derivative[2][xC][t] == -((G*mC*mA*(xC[t] - xA[t]))/((xC[t] - xA[t])^2 + (yC[t] - yA[t])^2)^(3/2)) - (G*mC*mB*(xC[t] - xB[t]))/((xC[t] - xB[t])^2 + (yC[t] - yB[t])^2)^(3/2), mC*Derivative[2][yC][t] == -((G*mC*mA*(yC[t] - yA[t]))/((xC[t] - xA[t])^2 + (yC[t] - yA[t])^2)^(3/2)) - (G*mC*mB*(yC[t] - yB[t]))/((xC[t] - xB[t])^2 + (yC[t] - yB[t])^2)^(3/2), xA[0] == xA0, yA[0] == yA0, Derivative[1][xA][0] == vxA0, Derivative[1][yA][0] == vyA0, xB[0] == xB0, yB[0] == yB0, Derivative[1][xB][0] == vxB0, Derivative[1][yB][0] == vyB0, xC[0] == xC0, yC[0] == yC0, Derivative[1][xC][0] == vxC0, Derivative[1][yC][0] == vyC0 }, {xA, yA, xB, yB, xC, yC},{t, 0, time}, MaxSteps -\u0026gt; 100000] x1[t_] := Evaluate[xA[t] /. soln1[[1,1]]] y1[t_] := Evaluate[yA[t] /. soln1[[1,2]]] x2[t_] := Evaluate[xB[t] /. soln1[[1,3]]] y2[t_] := Evaluate[yB[t] /. soln1[[1,4]]] x3[t_] := Evaluate[xC[t] /. soln1[[1,5]]] y3[t_] := Evaluate[yC[t] /. soln1[[1,6]]] Manipulate[Show[ {ParametricPlot[ {{x1[t], y1[t]}, {x2[t], y2[t]}, {x3[t], y3[t]}}, {t, tmax - 0.5, tmax}, Axes -\u0026gt; False, PlotRange -\u0026gt; {{-0.55, 1.45}, {-0.55, 1.08}}, PlotStyle -\u0026gt; {Red, Green, Blue}, GridLines -\u0026gt; {Table[0.25*x + 0.07, {x, -100, 100}], Table[0.25*y + 0.01, {y, -100, 100}]}, GridLinesStyle -\u0026gt; Directive[LightGray]]}, {Graphics[{Opacity[0.7], EdgeForm[Directive[Black]], Red, Disk[{x1[tmax], y1[tmax]}, 0.03], Green, Disk[{x2[tmax], y2[tmax]}, 0.03], Blue, Disk[{x3[tmax], y3[tmax]}, 0.03]}]}, ImageSize -\u0026gt; 600], {tmax, 6.05, 16.05}] ","permalink":"https://brianweinstein.github.io/posts/20140425-three-body-problem/","summary":"Given the starting positions, velocities, and masses of three objects interacting via gravity, the classical three-body problem involves determining the motions of the three particles throughout time.\nWhatâ€™s cool about the three-body system is that itâ€™s impossible to solve for the motions of the objects exactly. That is, we canâ€™t write down an equation that describes the system. Instead of finding an exact solution, we solve the system numerically, which amounts to finding an accurate approximation.","title":"Three-Body Problem on a Plane"},{"content":"A Fourier series is a way to expand a periodic function in terms of sines and cosines. The Fourier series is named after Joseph Fourier, who introduced the series as he solved for a mathematical way to describe how heat transfers in a metal plate.\nThe GIFs above show the 8-term Fourier series approximations of the square wave and the sawtooth wave.\n Mathematica code:\nf[t_] := SawtoothWave[t] T = 1; nmax = 18; a0 = (2/T)*Integrate[f[t], {t, -(T/2), T/2}] anlist = Table[(2/T)*Integrate[f[t]*Cos[(2*Pi*n*t)/T], {t, -(T/2), T/2}], {n, 1, nmax}] bnlist = Table[(2/T)*Integrate[f[t]*Sin[(2*Pi*n*t)/T], {t, -(T/2), T/2}], {n, 1, nmax}] fs[t_, nmax_] := a0/2 + Sum[anlist[[n]]*Cos[(2*Pi*n*t)/T] + bnlist[[n]]*Sin[(2*Pi*n*t)/T], {n, 1, nmax}] Manipulate[Column[{Plot[{f[t], fs[t, nmax0]}, {t, -1, 1}, PlotRange -\u0026gt; All, AxesLabel -\u0026gt; {\u0026quot;t\u0026quot;, \u0026quot;f(t)\u0026quot;}, PlotStyle -\u0026gt; {{Thick, Black}, {Thick, Red}}, ImageSize -\u0026gt; 700, AspectRatio -\u0026gt; 1/2.8], Row[{\u0026quot;f(t)=\u0026quot;, fs[t, nmax0]}]}], {nmax0, 1, nmax, 1}] ","permalink":"https://brianweinstein.github.io/posts/20140423-fourier-series/","summary":"A Fourier series is a way to expand a periodic function in terms of sines and cosines. The Fourier series is named after Joseph Fourier, who introduced the series as he solved for a mathematical way to describe how heat transfers in a metal plate.\nThe GIFs above show the 8-term Fourier series approximations of the square wave and the sawtooth wave.\n Mathematica code:\nf[t_] := SawtoothWave[t] T = 1; nmax = 18; a0 = (2/T)*Integrate[f[t], {t, -(T/2), T/2}] anlist = Table[(2/T)*Integrate[f[t]*Cos[(2*Pi*n*t)/T], {t, -(T/2), T/2}], {n, 1, nmax}] bnlist = Table[(2/T)*Integrate[f[t]*Sin[(2*Pi*n*t)/T], {t, -(T/2), T/2}], {n, 1, nmax}] fs[t_, nmax_] := a0/2 + Sum[anlist[[n]]*Cos[(2*Pi*n*t)/T] + bnlist[[n]]*Sin[(2*Pi*n*t)/T], {n, 1, nmax}] Manipulate[Column[{Plot[{f[t], fs[t, nmax0]}, {t, -1, 1}, PlotRange -\u0026gt; All, AxesLabel -\u0026gt; {\u0026quot;t\u0026quot;, \u0026quot;f(t)\u0026quot;}, PlotStyle -\u0026gt; {{Thick, Black}, {Thick, Red}}, ImageSize -\u0026gt; 700, AspectRatio -\u0026gt; 1/2.","title":"Fourier Series"},{"content":"","permalink":"https://brianweinstein.github.io/archives/","summary":"Archives","title":"Archives"},{"content":"","permalink":"https://brianweinstein.github.io/posts/","summary":"Posts","title":"Posts"},{"content":"","permalink":"https://brianweinstein.github.io/search/","summary":"search","title":"Search"}]