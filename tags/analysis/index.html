<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>analysis | Brian Weinstein</title>

<meta name="keywords" content="" />
<meta name="description" content="hello! ğŸ‘‹">
<meta name="author" content="Brian Weinstein">
<link rel="canonical" href="https://www.brianweinstein.co/tags/analysis/" />
<link href="/assets/css/stylesheet.min.de32830eb8ae1cd98ed4969a69dfba5574d5dc0f3eedc0ce674e2dab15321e23.css" integrity="sha256-3jKDDriuHNmO1Jaaad&#43;6VXTV3A8&#43;7cDOZ04tqxUyHiM=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://www.brianweinstein.co/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.brianweinstein.co/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.brianweinstein.co/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.brianweinstein.co/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.brianweinstein.co/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.80.0" />
<link rel="alternate" type="application/rss&#43;xml" href="https://www.brianweinstein.co/tags/analysis/index.xml">


<meta property="og:title" content="analysis" />
<meta property="og:description" content="hello! ğŸ‘‹" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.brianweinstein.co/tags/analysis/" />
<meta property="og:image" content="https://www.brianweinstein.co/47"/>
<meta property="og:updated_time" content="2020-02-19T00:00:00+00:00" /><meta property="og:site_name" content="Brian Weinstein" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://www.brianweinstein.co/47"/>

<meta name="twitter:title" content="analysis"/>
<meta name="twitter:description" content="hello! ğŸ‘‹"/>




<script async src="https://www.googletagmanager.com/gtag/js?id=G-CPC9GR2VCM"></script>
<script>
if (location.hostname === "brianweinstein.co")
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-CPC9GR2VCM');
</script>

</head>

<body class="list" id="top">
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.brianweinstein.co/" accesskey="h" title="Brian Weinstein (Alt + H)">Brian Weinstein</a>
            <span class="logo-switches">
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://www.brianweinstein.co/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://www.brianweinstein.co/posts/" title="Writing">
                    <span>Writing</span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main"> 
<header class="page-header">
  <h1>analysis</h1>
</header>



<article class="post-entry tag-entry">
  
  <header class="entry-header">
    <h2>
      In defense of â€œnothing interestingâ€
    </h2>
  </header>
  <section class="entry-subtitle">
    <p>A tribute to useful, but less interesting research findings</p>
  </section>
  <section class="entry-content">
    <p>A few years ago as a Data Scientist I was presenting to co-workers an analysis Iâ€™d been working on. The presentation went fine and the work was well-received, but I could tell the group was a little underwhelmed. Towards the end of the presentation, one co-worker asked, â€œDid you find anything that surprised you? Anything we didnâ€™t already know?â€
I had uncovered some new information, but most of what Iâ€™d found was well-aligned with what we already thought to be true. Still, I understood their sentiment. Any Data Scientist or Researcher will tell you that the most common thing we find when analyzing a dataset isâ€¦ nothing interesting. It happens constantly. Many of our findings corroborate what we and our business partners already thought to be true, even when weâ€™ve asked the right question. This can be frustrating for Data Scientists, Researchers, and our partners, but finding â€œnothing interestingâ€ is very different from finding â€œnothing useful,â€ and Iâ€™m a strong believer that finding nothing interesting after asking the right question is still worthy of celebration.
The Utility-Interest plane Before diving in, I want to emphasize the difference between a result being interesting and a result being useful. All analytical results (and the questions that spawned them) will fall somewhere in the Utility-Interest plane.
A. Useful results that are also interesting are the holy grail. Findings from these analyses drum up tons of excitement with stakeholders and have the potential to create a huge impact.
B. Useful results that arenâ€™t too interesting are less exciting, but are equally valuable! These are the only types of uninteresting results that are still defensible (the main topic of this post!). Useful, yet uninteresting results often arise when evaluating a hypothesis that everyone had assumed to be true, or when tackling a question thatâ€™d been answered through other methods in the past.
C. Useless results that arenâ€™t very interesting are just a poor use of time. These come from asking the wrong question, and a question to which everyone already knew the answer. These wonâ€™t gain much traction with stakeholders, and the primary downside is just wasting your own time.
D. Useless, but interesting results are dangerous. Very dangerous! Useless, yet interesting results arise when finding an exciting answer to the wrong question. Stakeholders can latch onto these findings and invest their own time into addressing a topic that should be lower priority.
By finding â€œnothing interestingâ€ in the data (i.e., a result in quadrant B) and presenting it to your stakeholders, youâ€™re able to make decisions with more confidence, ask meaningful follow-up questions, and increase stakeholdersâ€™ trust in using data in the future.
Knowing when your intuition is right is just as important as knowing when itâ€™sÂ wrong Asking a question of the data means youâ€™re unsure about something: maybe a course of action to take, the reason behind something happening, or something else. Exploring a dataset and finding no surprises just means that, in this case, your intuition wasnâ€™t too far off.
Even when you and your business partners have some intuition about a problem area, evaluating your hypotheses with data will let you know, without a doubt, if your hypotheses were true. Knowing when youâ€™re right is just as important as knowing when youâ€™re not, and by evaluating your hypotheses youâ€™ve learned to either maintain or change course.
Asking meaningful follow-ups Assuming you asked a worthwhile question of the data, finding â€œnothing interestingâ€ will help inform what questions you should ask in the future. Any useful findingâ€Šâ€”â€Šwhether interesting or notâ€Šâ€”â€Šgives you more confidence in the problem area and refines your area of focus, helping you to ask better questions going forward.
Reinforcing confidence inÂ data Findings that contradict our intuition can be hard to acceptâ€Šâ€”â€Šespecially when the findings tell us that not only was our intuition wrong, but that our actions or plans were too. By finding and presenting â€œnothing interesting,â€ you help build trust between your stakeholders and the data, making it easier for them to accept information from you in the future, especially when itâ€™s counter to some of their beliefs.
What to doÂ now Ask the right questions of your data. Of course, the points above only hold true if youâ€™ve asked the right question in the first place. Poor questions can sometimes lead to interesting answers, but the usefulness of these answers will be limited. My favorite way to refine a research question is to brainstorm with a cross-functional group of stakeholders (plus with this approach, you get stakeholder buy-in at the same time).
Celebrate â€œnothing interesting.â€ A finding doesnâ€™t have to be interesting in order to be useful. Next time you find â€œnothing interesting,â€ remember to celebrate it.
 Further reading For resources on asking good questions, I really like Asking Great Questions as a Data Scientist by Kristen Kehrer, and How to solve a business problem using data by Laura Ellis. (Please let me know if you have any others!)
...</p>
  </section>
  <footer class="entry-footer">

Feb 19, 2020&nbsp;Â·&nbsp;Brian Weinstein
</footer>
  <a class="entry-link" aria-label="post link to In defense of â€œnothing interestingâ€" href="https://www.brianweinstein.co/posts/20200219-in-defense-of-nothing-interesting/"></a>
</article>
<article class="post-entry tag-entry">
  
  <header class="entry-header">
    <h2>
      Speaking like a president
    </h2>
  </header>
  <section class="entry-subtitle">
    <p>Natural language processing on the first 2016 presidential debate</p>
  </section>
  <section class="entry-content">
    <p>The first debate in the 2016 presidential race was held on September 26. Itâ€™s no secret that Clinton and Trump are running on drastically different platforms, but how do they compare when it comes to their speech patterns and word choice? To quantify this, I dug into the data, using the debate transcript and natural language processing.
I measured the sentiment of Clintonâ€™s and Trumpâ€™s responses, and examined how emotional their words were throughout the debate. I also looked at each candidateâ€™s most commonly used adjectives. Building off the work ofÂ Alvin Chang at Vox, I was also able to examine how the speech patterns of Clinton and Trump each changed when directly responding to and when skirting the questions.
Sentiment Using theÂ Google Cloud Natural Language API, I measured the sentiment of each candidateâ€™s answers. TheÂ polarityÂ of a response is a measure of how positive or negative it is, and theÂ magnitudeÂ indicates how much emotion the words convey. The chart below shows the polarity of each candidateâ€™s responses, weighted by the magnitude.
Trump and Clinton matched each otherâ€™s polarity for the first half of the debate, but after his defense of stop-and-frisk around 9:50 PM, Trumpâ€™s words became much more negative.
Throughout the rest of the debate â€” during the questions on birtherism, cyber security, homegrown terrorism, nuclear weapons, and Clintonâ€™s looks and stamina â€” Clinton became more positive and Trump more negative.
The combination of polarity and magnitudeÂ gives us the best understanding of each lineâ€™s overall sentiment, and each candidateâ€™s most positive and negative responses are postedÂ here.
Braggadocios, and other adjectives I was also interested in the adjectives each candidate used most frequently during the debate. Using syntax analysis to extract each wordâ€™s part of speech, I identified the most-used adjectives of each candidate.
Answers vs non-answers AsÂ ChangÂ found, the candidates spent a lot of timeÂ notÂ answering Holtâ€™s questions â€” 48% of Clintonâ€™s words and a whopping 69% of Trumpâ€™s words were used in non-answers â€” and using the data Chang compiled, I was able to look at how the candidateâ€™s speech patterns differed when answering and not answering the questions.
Sentence subjects (â€œI alone can fix itâ€) Using part-of-speech tagging, I also identified theÂ subjectsÂ of each candidateâ€™s sentences. Clinton was more inclusive in her words, but only when directly responding to questions â€” using the plural â€œweâ€ more frequently than the singular â€œIâ€ â€” and the the opposite was true for her when avoiding a response. Trump, on the other hand, was always more likely to use â€œIâ€ over â€œweâ€.
Non-answer phrases The words each candidate used when directly answering the questions are all, unsurprisingly, highly related to the questions Holt asked. Whatâ€™s interesting here are the topics the candidates defaulted to when avoiding a response.
  A handful of my findings didnâ€™t make it into this post. If youâ€™re interested in more, thereâ€™s some additional analysis, including multiple classification models, in the projectâ€™sÂ GitHub repo. The text of this article (excluding this sentence) has polarity -0.4 and magnitude 15.5, so despite my best efforts itâ€™s leaningÂ slightlyÂ negative. Many thanks toÂ Alvin Chang and VoxÂ for their permission to use their annotated transcript, and toÂ Kelsey SchererÂ for designing the charts and lead image. Analysis was performed in R. Plots were generated using ggplot2, and then styled by Scherer using Sketch. The sentiment scores, part of speech tags, and all of the other NLP datasets can be found in theÂ GitHub repo.  ...</p>
  </section>
  <footer class="entry-footer">

Oct 3, 2016&nbsp;Â·&nbsp;Brian Weinstein
</footer>
  <a class="entry-link" aria-label="post link to Speaking like a president" href="https://www.brianweinstein.co/posts/20161003-debate-nlp/"></a>
</article>
<article class="post-entry tag-entry">
  
  <header class="entry-header">
    <h2>
      Mapping the frozen yogurt shop closest to each Manhattan apartment
    </h2>
  </header>
  <section class="entry-subtitle">
    <p></p>
  </section>
  <section class="entry-content">
    <p>I love frozen yogurt. When I first moved to New York three years ago, I lived only 1/8th of a mile from the closest froyo shop. The convenience of this 4-minute walk is something I neither appreciated nor utilized enough at the time.
After moving to Harlem last year, itâ€™s been harder than ever to satisfy my near-constant craving for this cold candy soup â€” Iâ€™m now a 24-minute walk to the nearest frozen yogurt.
As someone who loves data and has too much time to spare, I decided to find the locations in Manhattan with highest and lowest froyo densitiy. Inspired by Ben Wellingtonâ€™s work onÂ I Quant NY, I calculated the distance from every lot in Manhattan to the nearest froyo shopÂ and mapped it out.
https://brianweinstein.cartodb.com/viz/27dd05e0-2486-11e6-98ba-0e98b61680bf/embed_map
The highest density of froyo is right around West 33rd St. and 8th Ave., with three shops within a 1-block radius. The lowest density is right in Harlem. The red circle on the map shows the location farthest from frozen yogurt. The record belongs toÂ 700 Esplanade Gardens Plaza, a co-op right by the 145th St. stop on the 3-train, with a 51-minute trek across Manhattan to the Pinkberry by Columbia.
The mapÂ shows all of the froyo shops in Manhattan, and you can click onÂ any lot to find the distance to the closest shop.
  R code posted here. All distances in the map are measured usingÂ great-circle distanceÂ (i.e., â€as the crow fliesâ€), according to theÂ law of cosines. Frozen yogurt locations were found via theÂ Google Places Nearby Search API. The API returned some non-froyo-exclusive shops like Ben and Jerryâ€™s, which I kept in the dataset since they technically serve some frozen yogurt (although we all know these shops donâ€™tÂ reallyÂ count). I only included froyo shops that were in Manhattan, so some lots may have a closer shop than the one listed if we include those in other boroughs. Manhattan lot locations are fromÂ PLUTO. The map was created usingÂ CartoDB. Tons of inspiration for this came from Ben Wellingtonâ€™s work onÂ I Quant NY.  ...</p>
  </section>
  <footer class="entry-footer">

May 31, 2016&nbsp;Â·&nbsp;Brian Weinstein
</footer>
  <a class="entry-link" aria-label="post link to Mapping the frozen yogurt shop closest to each Manhattan apartment" href="https://www.brianweinstein.co/posts/20160531-froyo-nyc/"></a>
</article>

    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://www.brianweinstein.co/">Brian Weinstein</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                behavior: "smooth"
            });
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.replaceState(null, null, `#${id}`);
            }
        });
    });
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>

</body>

</html>
